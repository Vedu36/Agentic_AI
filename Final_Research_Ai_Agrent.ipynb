{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "838a4c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import wikipediaapi\n",
    "from groq import Groq\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3844da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Groq client\n",
    "api_key = \"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\"\n",
    "client = Groq(api_key=api_key)\n",
    "\n",
    "# Initialize vectorizer model for optional vectorization\n",
    "vectorizer = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb34c2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to interact with Groq API\n",
    "def generate_response(prompt):\n",
    "    chat_completion = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        model=\"llama3-70b-8192\"\n",
    "    )\n",
    "    return chat_completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2729ab7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to fetch data from ArXiv API\n",
    "def fetch_from_arxiv(query):\n",
    "    response = requests.get(f\"https://export.arxiv.org/api/query?search_query={query}\")\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52f2627c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to fetch data from Wikipedia API\n",
    "def fetch_from_wikipedia(query):\n",
    "    wiki_wiki = wikipediaapi.Wikipedia(\n",
    "        language='en',\n",
    "        user_agent='AI-KnowledgeAgent/1.0 (Contact: your-email@example.com)'\n",
    "    )\n",
    "    page = wiki_wiki.page(query)\n",
    "    if page.exists():\n",
    "        return page.summary\n",
    "    else:\n",
    "        return f\"Wikipedia page for '{query}' not found.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c5d00e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to fetch data from DuckDuckGo API\n",
    "def fetch_from_duckduckgo(query):\n",
    "    response = requests.get(f\"https://api.duckduckgo.com/?q={query}&format=json\")\n",
    "    return response.json().get('AbstractText', \"No relevant data found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5d7d058",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to send tool results through the LLM for refinement\n",
    "def refine_tool_results(tool_name, raw_data):\n",
    "    prompt = f\"\"\"\n",
    "    Task: Analyze and refine the following data extracted from {tool_name}.\n",
    "    Raw Data: \"{raw_data}\"\n",
    "    \n",
    "    Provide a clear and concise summary of the key points.\n",
    "    \"\"\"\n",
    "    return generate_response(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d8f1e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to split data into batches\n",
    "def split_into_batches(data, batch_size=2000):\n",
    "    return [data[i:i + batch_size] for i in range(0, len(data), batch_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a503572",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process and summarize batched data\n",
    "def process_batches(tool_name, data, batch_size=2000):\n",
    "    batches = split_into_batches(data, batch_size)\n",
    "    batch_summaries = []\n",
    "    \n",
    "    for i, batch in enumerate(batches):\n",
    "        prompt = f\"\"\"\n",
    "        Task: Summarize the following batch of data extracted from {tool_name}.\n",
    "        Batch {i + 1}/{len(batches)}:\n",
    "        \"{batch}\"\n",
    "\n",
    "        Provide a concise summary.\n",
    "        \"\"\"\n",
    "        summary = generate_response(prompt)\n",
    "        batch_summaries.append(summary)\n",
    "\n",
    "    # Combine summaries from all batches\n",
    "    combined_summary = \" \".join(batch_summaries)\n",
    "    return combined_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed85b876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to vectorize data\n",
    "def vectorize_data(data):\n",
    "    return vectorizer.encode(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5046bfc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main workflow\n",
    "def main():\n",
    "    user_query = input(\"Enter your query: \")\n",
    "    \n",
    "    # Step 1: Generate initial response using Groq API\n",
    "    initial_response = generate_response(user_query)\n",
    "    print(\"Initial Response from Groq API:\\n\", initial_response)\n",
    "    \n",
    "    # Step 2: Extract data from tools\n",
    "    print(\"\\nFetching data from ArXiv...\")\n",
    "    arxiv_data = fetch_from_arxiv(user_query)\n",
    "    print(\"Fetching data from Wikipedia...\")\n",
    "    wikipedia_data = fetch_from_wikipedia(user_query)\n",
    "    print(\"Fetching data from DuckDuckGo...\")\n",
    "    duckduckgo_data = fetch_from_duckduckgo(user_query)\n",
    "    \n",
    "    # Step 3: Refine each tool's data individually through the LLM\n",
    "    print(\"\\nRefining data from ArXiv...\")\n",
    "    arxiv_summary = process_batches(\"ArXiv\", arxiv_data) if len(arxiv_data) > 2000 else refine_tool_results(\"ArXiv\", arxiv_data)\n",
    "    print(\"ArXiv Summary:\\n\", arxiv_summary)\n",
    "\n",
    "    print(\"\\nRefining data from Wikipedia...\")\n",
    "    wikipedia_summary = process_batches(\"Wikipedia\", wikipedia_data) if len(wikipedia_data) > 2000 else refine_tool_results(\"Wikipedia\", wikipedia_data)\n",
    "    print(\"Wikipedia Summary:\\n\", wikipedia_summary)\n",
    "\n",
    "    print(\"\\nRefining data from DuckDuckGo...\")\n",
    "    duckduckgo_summary = process_batches(\"DuckDuckGo\", duckduckgo_data) if len(duckduckgo_data) > 2000 else refine_tool_results(\"DuckDuckGo\", duckduckgo_data)\n",
    "    print(\"DuckDuckGo Summary:\\n\", duckduckgo_summary)\n",
    "    \n",
    "    # Step 4: Optionally vectorize data (if needed)\n",
    "    arxiv_vector = vectorize_data(arxiv_summary) if arxiv_summary else None\n",
    "    wikipedia_vector = vectorize_data(wikipedia_summary) if wikipedia_summary else None\n",
    "    duckduckgo_vector = vectorize_data(duckduckgo_summary) if duckduckgo_summary else None\n",
    "\n",
    "    # Step 5: Combine tool summaries into a final summary\n",
    "    final_prompt = f\"\"\"\n",
    "    Task: Summarize the collective insights from multiple tools.\n",
    "    \n",
    "    Insights:\n",
    "    - ArXiv Summary: {arxiv_summary}\n",
    "    - Wikipedia Summary: {wikipedia_summary}\n",
    "    - DuckDuckGo Summary: {duckduckgo_summary}\n",
    "    \n",
    "    Provide a well-structured final summary that integrates all the insights.\n",
    "    \"\"\"\n",
    "    final_response = generate_response(final_prompt)\n",
    "    print(\"\\nFinal Summarized Response:\\n\", final_response)\n",
    "\n",
    "    # Step 6: Offer to save the final response as notes\n",
    "    save_notes = input(\"\\nDo you want to save this response as a file for notes? (yes/no): \").strip().lower()\n",
    "    if save_notes == \"yes\":\n",
    "        file_name = input(\"Enter the filename (e.g., notes.txt): \").strip()\n",
    "        try:\n",
    "            with open(file_name, \"w\") as file:\n",
    "                file.write(\"Query:\\n\" + user_query + \"\\n\\n\")\n",
    "                file.write(\"ArXiv Summary:\\n\" + arxiv_summary + \"\\n\\n\")\n",
    "                file.write(\"Wikipedia Summary:\\n\" + wikipedia_summary + \"\\n\\n\")\n",
    "                file.write(\"DuckDuckGo Summary:\\n\" + duckduckgo_summary + \"\\n\\n\")\n",
    "                file.write(\"Final Response:\\n\" + final_response + \"\\n\")\n",
    "            print(f\"Response saved successfully in {file_name}.\")\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred while saving the file: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f8e0bb3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your query: RAG latest papers\n",
      "Initial Response from Groq API:\n",
      " RAG (Reinforcement Learning with Attention Guidance) is a research paper that combines reinforcement learning with attention mechanisms to improve the learning efficiency and effectiveness in complex environments. Here are some of the latest papers related to RAG:\n",
      "\n",
      "1. **\"Reinforcement Learning with Attention Guidance\"** by Zhang et al. (2020)\n",
      "\n",
      "This is the original paper that introduced the RAG algorithm. The authors propose using attention mechanisms to guide the exploration in reinforcement learning, and they show that RAG can achieve better performance than traditional reinforcement learning methods in several environments.\n",
      "\n",
      "2. **\"Hierarchical Reinforcement Learning with Attention Guidance\"** by Li et al. (2021)\n",
      "\n",
      "This paper extends the RAG algorithm to hierarchical reinforcement learning settings. The authors propose using attention mechanisms to guide the learning of sub-policies in a hierarchical reinforcement learning framework, and they show that their approach can achieve better performance than traditional hierarchical reinforcement learning methods.\n",
      "\n",
      "3. **\"Attention-Guided Deep Reinforcement Learning for Partially Observable Environments\"** by Wang et al. (2021)\n",
      "\n",
      "This paper applies RAG to partially observable environments, where the agent does not have access to the full state of the environment. The authors propose using attention mechanisms to guide the learning of a deep reinforcement learning agent in such environments, and they show that their approach can achieve better performance than traditional deep reinforcement learning methods.\n",
      "\n",
      "4. **\"RAG-Q: Reinforcement Learning with Attention Guidance and Q-Network\"** by Chen et al. (2021)\n",
      "\n",
      "This paper combines RAG with Q-networks, which are a type of value-based reinforcement learning method. The authors propose using attention mechanisms to guide the learning of the Q-network, and they show that their approach can achieve better performance than traditional Q-network methods.\n",
      "\n",
      "5. **\"Multi-Agent Reinforcement Learning with Attention Guidance\"** by Liu et al. (2021)\n",
      "\n",
      "This paper applies RAG to multi-agent reinforcement learning settings, where multiple agents interact with each other in a shared environment. The authors propose using attention mechanisms to guide the learning of each agent, and they show that their approach can achieve better performance than traditional multi-agent reinforcement learning methods.\n",
      "\n",
      "These papers demonstrate the effectiveness of RAG in various reinforcement learning settings, and they provide insights into how attention mechanisms can be used to improve the learning efficiency and effectiveness in complex environments.\n",
      "\n",
      "Fetching data from ArXiv...\n",
      "Fetching data from Wikipedia...\n",
      "Fetching data from DuckDuckGo...\n",
      "\n",
      "Refining data from ArXiv...\n",
      "ArXiv Summary:\n",
      " Here is a concise summary of the extracted data:\n",
      "\n",
      "The ArXiv query \"RAG latest papers\" retrieved 688,423 results. The first result is a paper titled \"Auto-RAG: Autonomous Retrieval-Augmented Generation for Large Language Models\". The paper introduces Auto-RAG, a model that autonomously retrieves and refines knowledge using iterative retrieval, leveraging the decision-making capabilities of Large Language Models (LLMs) to gather valuable external information. Here is a concise summary of the batch of data extracted from ArXiv:\n",
      "\n",
      "The batch appears to describe two related papers on Retrieval-Augmented Generation (RAG) systems for Large Language Models (LLMs).\n",
      "\n",
      "Paper 1: \"Auto-RAG\" is an autonomous system that synthesizes reasoning-based decision-making instructions for iterative retrieval and fine-tuning of LLMs. It achieves outstanding performance across six benchmarks, can adjust the number of iterations based on question difficulty and retrieved knowledge utility, and provides an interpretable and intuitive experience.\n",
      "\n",
      "Paper 2: \"Modular RAG\" transforms RAG systems into reconfigurable frameworks, enhancing the capabilities of LLMs in knowledge-intensive tasks. (The summary is incomplete, but it seems to focus on improving RAG systems.)\n",
      "\n",
      "Both papers appear to focus on advancing the capabilities of LLMs through innovative RAG systems. Here is a concise summary of the batch of data:\n",
      "\n",
      "The paper discusses the limitations of the traditional \"retrieve-then-generate\" paradigm in Retrieval-Augmented Generation (RAG) systems and proposes a modular RAG framework that decomposes complex systems into independent modules and operators. This modular approach allows for a more reconfigurable and advanced design, integrating routing, scheduling, and fusion mechanisms. The paper also identifies common RAG patterns and provides a comprehensive analysis of their implementation nuances. The authors suggest that this modular framework will enable the development of new operators and paradigms, paving the way for the continued evolution and practical deployment of RAG technologies. The paper surveys the recent advancements in Retrieval-Augmented Large Language Models (RA-LLMs), which combine the capabilities of Large Language Models (LLMs) with the power of retrieval-augmented generation (RAG) to provide up-to-date and reliable external knowledge. The survey covers three primary technical perspectives: architectures, training strategies, and applications. It reviews existing research studies, highlighting the challenges and capabilities of RA-LLMs, and discusses current limitations and promising directions for future research. Batch 5/12 consists of two ArXiv entries. \n",
      "\n",
      "The first entry appears to be a survey paper on \"RAG Meets LLMs\" (RAG: Retrieval-Augmented Generation, LLMs: Long-Context Language Models) with a link to the survey and a comment mentioning that this is the long version of a paper accepted by KDD2024. The categories for this entry are Computer Science, Computation and Language, Artificial Intelligence, and Information Retrieval.\n",
      "\n",
      "The second entry is a research paper titled \"In Defense of RAG in the Era of Long-Context Language Models\". It discusses the role of Retrieval-Augmented Generation (RAG) in context-based answer generation, arguing that despite the emergence of long-context LLMs, RAG is still a reliable solution. It disagrees with recent studies that favor long-context LLMs over RAG in long-context applications. The two papers in this batch focus on improving Retrieval-Augmented Generation (RAG) for large language models (LLMs). The first paper proposes an Order-Preserve RAG (OP-RAG) mechanism that enhances answer quality in long-context question-answer applications by retrieving relevant information in a specific order. The authors find that OP-RAG can achieve higher answer quality with fewer tokens than traditional LLMs.\n",
      "\n",
      "The second paper, MultiHop-RAG, benchmarks RAG for multi-hop queries that require retrieving and reasoning over multiple pieces of information. The authors find that existing RAG systems are inadequate for these types of queries and propose improvements to mitigate this limitation. Here is a concise summary of the extracted ArXiv batch:\n",
      "\n",
      "The authors, Yixuan Tang and Yi Yang, created a novel dataset called MultiHop-RAG, which focuses on multi-hop queries in Reasoning-Augmented Generation (RAG) systems. This dataset includes a knowledge base, multi-hop queries, ground-truth answers, and supporting evidence. The authors demonstrate the dataset's utility through two experiments, showing that existing RAG methods struggle with multi-hop queries. The dataset and an implemented RAG system are publicly available on GitHub. This paper compares Retrieval Augmented Generation (RAG) and long-context Large Language Models (LLMs) in processing lengthy contexts. The study finds that while LLMs like Gemini-1.5 and GPT-4 can understand long contexts directly, RAG is more computationally efficient. The authors propose a hybrid approach called Self-Route, which selectively uses RAG or LLMs based on model self-reflection, achieving a balance between performance and computational cost. The research provides guidelines for long-context applications of LLMs using RAG and LLMs. Here is a concise summary of the extracted data:\n",
      "\n",
      "The paper \"LLM4VV: Developing LLM-Driven Testsuite for Compiler Validation\" explores the use of large language models (LLMs) to automatically generate tests for validating compiler implementations of the OpenACC parallel programming paradigm. The authors fine-tuned various open-source and closed-source LLMs, including Meta Codellama, Deepseek Coder, and OpenAI GPT-3.5-Turbo and GPT-4-Turbo, and evaluated their performance using different prompt engineering techniques. The results show that the LLM Deepseek-Coder-33b-Instruct produced the most passing tests, followed by GPT-4-Turbo. The paper contributes to the field by exploring the capabilities of LLMs for code generation, investigating fine-tuning and prompt methods, and analyzing the outcome of generated tests. This batch of data from ArXiv contains information about three research papers:\n",
      "\n",
      "1. The first paper (ID: 2310.04963v3) is categorized under \"cs.AI\" (Artificial Intelligence) and does not have a title or summary provided.\n",
      "2. The second paper (ID: 2404.00657v1) is titled \"Observations on Building RAG Systems for Technical Documents\" and explores the challenges of building Retrieval Augmented Generation (RAG) systems for technical documents. The paper reviews prior art, performs experiments, and highlights best practices and potential challenges. It is categorized under \"cs.LG\" (Learning), \"cs.AI\" (Artificial Intelligence), \"cs.CL\" (Computation and Language), and \"I.2.7\" (Natural Language Processing).\n",
      "3. The third paper (ID: 2403.05676v1) is titled \"PipeRAG: Fast Retrieval-Augmented Generation\" but the summary is cut off.\n",
      "\n",
      "In summary, these papers are related to Artificial Intelligence, Machine Learning, and Natural Language Processing, with a focus on Retrieval Augmented Generation systems and their applications. Here is a concise summary of the data:\n",
      "\n",
      "**Title:** Algorithm-System Co-design for Efficient Retrieval-Augmented Generation\n",
      "\n",
      "**Summary:** The authors propose PipeRAG, a novel approach that reduces generation latency and enhances generation quality in large language models. PipeRAG uses pipeline parallelism, flexible retrieval intervals, and a performance model to balance retrieval quality and latency. The approach achieves up to 2.6x speedup in end-to-end generation latency while improving generation quality.\n",
      "\n",
      "**Authors:** Wenqi Jiang, Shuai Zhang, Boran Han, Jie Wang, Bernie Wang, and Tim Kraska Here is a concise summary of the paper:\n",
      "\n",
      "Title: Evaluation of Semantic Search and its Role in Retrieved-Augmented-Generation (RAG) for Arabic Language\n",
      "\n",
      "Authors: Ali Mahboub, Muhy Eddin Za'ter, Bashar Al-Rfooh, Yazan Estaitia, Adnan Jaljuli, and Asma Hakouz\n",
      "\n",
      "Summary: The paper aims to establish a benchmark for semantic search in Arabic language, which is a complex task due to the lack of standard benchmarks and the multifaceted nature of the task. The authors evaluate the effectiveness of semantic search metrics and dataset within the framework of retrieval augmented generation (RAG). The research focuses on addressing the challenges of semantic search in Arabic language.\n",
      "\n",
      "Refining data from Wikipedia...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wikipedia Summary:\n",
      " After analyzing the raw data, here is a clear and concise summary of the key points:\n",
      "\n",
      "**Summary:** \n",
      "\n",
      "* There is no Wikipedia page for \"RAG latest papers\".\n",
      "* The search query yielded no results.\n",
      "\n",
      "In other words, the data suggests that there is no existing Wikipedia page dedicated to \"RAG latest papers\". If you're looking for information on RAG (whatever RAG stands for), you might need to search elsewhere or create a new Wikipedia page on the topic.\n",
      "\n",
      "Refining data from DuckDuckGo...\n",
      "DuckDuckGo Summary:\n",
      " I apologize, but it seems that there is no data to analyze and refine. The raw data provided is an empty string.\n",
      "\n",
      "If you meant to provide actual data, please paste it, and I'll be happy to help you analyze and refine it, providing a clear and concise summary of the key points.\n",
      "\n",
      "Final Summarized Response:\n",
      " Here is a well-structured final summary that integrates all the insights from the multiple tools:\n",
      "\n",
      "**Retrieval-Augmented Generation (RAG) for Large Language Models (LLMs): A Comprehensive Summary**\n",
      "\n",
      "The collective insights from the analyzed data suggest that Retrieval-Augmented Generation (RAG) is a rapidly advancing field in Natural Language Processing (NLP), particularly in the context of Large Language Models (LLMs). The following key points summarize the main findings:\n",
      "\n",
      "**Advancements in RAG Systems**\n",
      "\n",
      "* Auto-RAG: A novel autonomous system that synthesizes reasoning-based decision-making instructions for iterative retrieval and fine-tuning of LLMs, achieving outstanding performance across six benchmarks.\n",
      "* Modular RAG: A reconfigurable framework that enhances the capabilities of LLMs in knowledge-intensive tasks by decomposing complex systems into independent modules and operators.\n",
      "* Order-Preserve RAG (OP-RAG): A mechanism that enhances answer quality in long-context question-answer applications by retrieving relevant information in a specific order.\n",
      "* MultiHop-RAG: A benchmark for multi-hop queries that require retrieving and reasoning over multiple pieces of information, with improvements proposed to mitigate existing limitations.\n",
      "\n",
      "**RAG vs. Long-Context LLMs**\n",
      "\n",
      "* A study comparing RAG and long-context LLMs in processing lengthy contexts found that while LLMs can understand long contexts directly, RAG is more computationally efficient.\n",
      "* A hybrid approach called Self-Route, which selectively uses RAG or LLMs based on model self-reflection, achieves a balance between performance and computational cost.\n",
      "\n",
      "**Applications of RAG and LLMs**\n",
      "\n",
      "* LLM4VV: A novel approach that explores the use of LLMs to automatically generate tests for validating compiler implementations of the OpenACC parallel programming paradigm.\n",
      "* Observations on Building RAG Systems for Technical Documents: A paper that reviews prior art, performs experiments, and highlights best practices and potential challenges in building RAG systems for technical documents.\n",
      "* PipeRAG: A novel approach that reduces generation latency and enhances generation quality in large language models using pipeline parallelism, flexible retrieval intervals, and a performance model.\n",
      "\n",
      "**Semantic Search and RAG in Arabic Language**\n",
      "\n",
      "* A paper evaluates the effectiveness of semantic search metrics and datasets within the framework of retrieval augmented generation (RAG) for the Arabic language, addressing the challenges of semantic search in this context.\n",
      "\n",
      "**Lack of Wikipedia Page**\n",
      "\n",
      "* There is no existing Wikipedia page dedicated to \"RAG latest papers\", indicating a need for creating a new page on the topic.\n",
      "\n",
      "In conclusion, the collective insights highlight the rapid advancements in RAG systems, their applications, and their comparisons with long-context LLMs. The field is continuously evolving, with new approaches and techniques being proposed to improve the capabilities of LLMs in knowledge-intensive tasks.\n",
      "\n",
      "Do you want to save this response as a file for notes? (yes/no): yes\n",
      "Enter the filename (e.g., notes.txt): Rag_research\n",
      "Response saved successfully in Rag_research.\n"
     ]
    }
   ],
   "source": [
    "# Execute the workflow\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
